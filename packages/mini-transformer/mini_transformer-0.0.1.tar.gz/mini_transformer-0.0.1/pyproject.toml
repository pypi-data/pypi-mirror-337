[project]
name = 'mini_transformer'
version = '0.0.1'
authors = [
    {name = 'ztw', email = '1837669410@qq.com'}
]
description = 'An advanced minimal transformer component framework'
readme = 'README.md'
requires-python = '>= 3.10'
license = {text = 'MIT'}
keywords = [
    'artificial intelligence',
    'deep learning',
    'transformer',
    'attention mechanism',
    'GQA',
    'MLA',
    'rotary embedding'
]
classifiers=[
    'Development Status :: 4 - Beta',
    'Intended Audience :: Developers',
    'Topic :: Scientific/Engineering :: Artificial Intelligence',
    'License :: OSI Approved :: MIT License',
    'Programming Language :: Python :: 3.10',
]
dependencies = [
    'numpy >= 2.2.4',
    'einops >= 0.8.1'
]

[project.urls]
Repository = 'https://github.com/LemonAttn/mini_transformer'

[build-system]
requires = ['hatchling']
build-backend = 'hatchling.build'

[tool.hatch.metadata]
allow-direct-references = true

[tool.hatch.build.targets.wheel]
packages = ['mini_transformer']