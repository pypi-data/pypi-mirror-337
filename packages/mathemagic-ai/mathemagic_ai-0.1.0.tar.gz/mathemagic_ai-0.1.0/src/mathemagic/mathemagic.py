import os
import re
import io
import sys
import contextlib
from pathlib import Path
from typing import Tuple, Optional

import anthropic
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get API key from environment variables
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
if not ANTHROPIC_API_KEY:
    raise ValueError("ANTHROPIC_API_KEY environment variable is not set")

# Initialize Anthropic client
client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

def load_system_prompt() -> str:
    """Load the system prompt from the system_instruction.md file."""
    current_dir = Path(__file__).parent
    system_instruction_path = current_dir / "system_instruction.md"
    
    try:
        with open(system_instruction_path, "r") as file:
            return file.read()
    except FileNotFoundError:
        # Fallback to a basic system prompt if the file is not found
        return """You are a helpful assistant that converts natural language math problems into Python code.
Please solve the math problem by writing Python code. Use the Pint library for unit conversions.
Return only the Python code without any explanations."""

# Load system prompt once when module is imported
SYSTEM_PROMPT = load_system_prompt()

def prompt_to_py(user_prompt: str, system_prompt: Optional[str] = None) -> str:
    """
    Convert a user prompt to Python code using the Anthropic API.
    
    Args:
        user_prompt: The user's math problem or question
        system_prompt: Optional system prompt to override the default
        
    Returns:
        The Python code generated by the LLM
    """
    if system_prompt is None:
        system_prompt = SYSTEM_PROMPT
    
    # Combine system prompt and user prompt
    full_prompt = f"{user_prompt}"
    
    # Call Anthropic API
    message = client.messages.create(
        model="claude-3-opus-20240229",
        max_tokens=1000,
        system=system_prompt,
        messages=[
            {"role": "user", "content": full_prompt}
        ]
    )
    
    # Extract the response
    response = message.content[0].text
    
    return response

def extract_python_code(response: str) -> str:
    """
    Extract Python code from the LLM response.
    
    Args:
        response: The response from the LLM
        
    Returns:
        The extracted Python code
    """
    # Look for Python code blocks in the response
    pattern = r"```python\s*(.*?)\s*```"
    matches = re.findall(pattern, response, re.DOTALL)
    
    if matches:
        return matches[0]
    else:
        # If no code block is found, assume the entire response is code
        return response

def execute_py(response: str) -> Tuple[str, bool]:
    """
    Execute the Python code extracted from the response.
    
    Args:
        response: The response containing Python code
        
    Returns:
        A tuple containing (execution_result, success_flag)
    """
    # Extract Python code
    code = extract_python_code(response)
    
    # Capture stdout to get the result
    stdout_capture = io.StringIO()
    success = True
    
    try:
        # Redirect stdout to capture print statements
        with contextlib.redirect_stdout(stdout_capture):
            # Add Pint imports at the beginning of the code
            pint_imports = """
from pint import UnitRegistry
ureg = UnitRegistry()
Q_ = ureg.Quantity
"""
            # Execute the code with the necessary imports
            exec(pint_imports + code)
            
        result = stdout_capture.getvalue().strip()
        if not result:
            result = "Code executed successfully but produced no output."
    except Exception as e:
        result = f"Error executing code: {str(e)}"
        success = False
    
    return result, success
