[API Reference](https://api.js.langchain.com/): LLM should read this page when (building JavaScript applications with language models) or (using LangChain.js for natural language processing tasks) or (developing language model agents and chains with composability). (Introduction to LangChain.js, a framework for building applications powered by language models. Covers installation, supported environments, key concepts like composability and agents, documentation, contributing, and relationship to Python LangChain.)

[Document](https://api.js.langchain.com/classes/_langchain_core.documents.Document.html/): LLM should read this page when (working with documents in LangChain.js, understanding the Document class, or handling document metadata). (This page describes the Document class in LangChain.js, which is an interface for interacting with documents and their metadata. It includes the class constructor, properties for document ID, metadata, and content, and type parameters.)

[StructuredTool](https://api.js.langchain.com/classes/_langchain_core.tools.StructuredTool.html/): LLM should read this page when (it needs to understand the StructuredTool class, or when creating or working with structured tools, or when integrating tools with Zod schemas). (This page covers the StructuredTool class, which is a base class for tools that accept input defined by a Zod schema. It includes properties like description, name, schema, and methods for invoking, streaming, and configuring the tool.)

[Agents](https://js.langchain.com/docs/concepts/agents/): LLM should read this page when (1) building an AI agent system, (2) exploring agent architectures, (3) migrating from legacy agents to LangGraph. (Overview of LangChain agents and LangGraph as a recommended solution for building customizable agents. Includes information on transitioning from the legacy AgentExecutor to LangGraph.)

[Architecture](https://js.langchain.com/docs/concepts/architecture/): LLM should read this page when (needing an overview of LangChain's architecture, planning to integrate a new component, developing advanced LLM applications) (Overview of LangChain's key packages and their roles: core abstractions, application architecture, popular integrations, community integrations, advanced orchestration with LangGraph, developer tooling with LangSmith)

[Callbacks](https://js.langchain.com/docs/concepts/callbacks/): LLM should read this page when (needing to hook into various stages of an LLM application) (logging, monitoring, or streaming events) (Covers callback events, callback handlers, and how to pass callbacks into modules)

[Conversation patterns](https://js.langchain.com/docs/concepts/chat_history/#conversation-patterns): LLM should read this page when (managing chat history in conversations with chat models) (configuring conversational agents for tool calling) (Explains chat history as a record of messages between user and assistant, and assistant and tools. Covers managing history length and conversation patterns/structures. Provides guidelines for preserving correct flow.)

[Context window](https://js.langchain.com/docs/concepts/chat_models/#context-window): LLM should read this page when (they are developing applications that use chat models) (they need to understand how to integrate chat models with other LangChain features) (Provides an overview of chat models, their features, integrations, and interfaces. Covers tool calling, structured outputs, multimodality, context windows, caching, and related resources.)

[Document Loaders](https://js.langchain.com/docs/concepts/document_loaders/): LLM should read this page when (1) looking to load data from various sources into LangChain, (2) needing to understand the document loading interface, (3) needing examples of how to use document loaders. (This page provides an overview of document loaders in LangChain, which are designed to load document objects from various data sources like files, websites, databases, etc. It covers the interface, available integrations, and related resources.)

[Embedding Models](https://js.langchain.com/docs/concepts/embedding_models/): Line 1: 'LLM should read this page when (1) learning about embedding models and their role in LangChain, (2) needing to understand how to measure text similarity, (3) seeking integrations for embedding models.' Line 2: '(Overview of embedding models, their purpose in transforming text into numerical representations, measuring similarity between embeddings, and available integrations in LangChain.)'

[Evaluation](https://js.langchain.com/docs/concepts/evaluation/): LLM should read this page when (evaluating the performance of an LLM application) (building reliable LLM applications) (understanding how LangSmith can help with evaluation) (The page covers the concept of evaluation for LLM applications, its importance, how LangSmith can help with creating datasets, defining metrics, tracking results over time, and running evaluations automatically or as part of CI/CD.)

[Example Selectors](https://js.langchain.com/docs/concepts/example_selectors/): LLM should read this page when (using few-shot examples with chat models, dynamically selecting examples for prompts) (Overview of example selectors for dynamically selecting and formatting examples into prompts for few-shot prompting with language models)

[Few-shot prompting](https://js.langchain.com/docs/concepts/few_shot_prompting/): Line 1: 'LLM should read this page when (1) using few-shot prompting, (2) wanting to improve model performance, (3) selecting and formatting examples for prompts' Line 2: '(Discusses techniques for few-shot prompting, including generating examples, determining number of examples, selecting relevant examples, and formatting examples in prompts)'

[LangChain Expression Language (LCEL)](https://js.langchain.com/docs/concepts/lcel/): Line 1: LLM should read this page when (composing sequences of operations, executing operations in parallel, working with LangChain Expression Language) Line 2: (Explains LangChain Expression Language (LCEL) for declaratively building chains of Runnables, benefits of LCEL, composition primitives like RunnableSequence and RunnableParallel, composition syntax using pipe method)

[HumanMessage](https://js.langchain.com/docs/concepts/messages/#humanmessage): Line 1: 'LLM should read this page when (managing chat histories, implementing chat interfaces, working with chat models)' Line 2: '(Overview of the structure and components of messages in chat models, including different message types, roles, content formats, and metadata)'

[Multimodality](https://js.langchain.com/docs/concepts/multimodality/): LLM should read this page when (working with multimodal data like images/audio/video, using multimodal chat models, or building multimodal search/retrieval systems) (Overview of multimodality in chat models, embedding models, and vector stores. Current limitations and future plans for supporting multimodal inputs/outputs.)

[Output Parsers](https://js.langchain.com/docs/concepts/output_parsers/): LLM should read this page when (needing to parse output from an LLM into structured formats, needing to normalize output from chat models and LLMs, needing to get structured data from an LLM) (The page covers output parsers in LangChain, which are responsible for transforming LLM output into structured formats like JSON, XML, CSV, etc. It lists the different output parsers available and their capabilities.)

[Prompt Templates](https://js.langchain.com/docs/concepts/prompt_templates/): LLM should read this page when (working with prompts for LLMs or chat models), (constructing prompt templates for different use cases). (Covers different types of prompt templates - string, chat, and using message placeholders. Explains formatting and invoking these templates.)

[Retrieval Augmented Generation (RAG)](https://js.langchain.com/docs/concepts/rag/): LLM should read this page when (building a question-answering system, integrating external data with LLMs, or developing advanced language model applications) (Overview of Retrieval Augmented Generation (RAG), which combines language models with external knowledge bases by retrieving relevant information and incorporating it into the model's prompt to improve response accuracy and currency)

[Retrieval](https://js.langchain.com/docs/concepts/retrieval/): LLM should read this page when (building question answering systems), (working with various data sources), (implementing natural language interfaces) (Overview of retrieval systems for unstructured data and structured data. Details on query analysis using models to construct or re-write queries. Information on different retrieval systems like vector indexes, databases, and LangChain's unified retriever interface.)

[Retrievers](https://js.langchain.com/docs/concepts/retrievers/): LLM should read this page when (needing to understand how to retrieve relevant documents from various sources) (seeking information on advanced retrieval patterns like ensembling and retaining source documents) (Overview of retrievers in LangChain) (Common types of retrievers including search APIs, databases, lexical search, and vector stores) (Advanced retrieval patterns like ensembling multiple retrievers and retaining source documents)

[invoke](https://js.langchain.com/docs/concepts/runnables/): LLM should read this page when (building custom LLM applications using the Runnable interface, composing Runnables together using LCEL, working with streaming APIs) (Overview of the Runnable interface, optimized batch execution, input/output types, RunnableConfig options like runName/tags/metadata/callbacks, creating Runnables from functions)

[stream](https://js.langchain.com/docs/concepts/streaming/): LLM should read this page when (building streaming LLM applications), (integrating chat models in real-time applications), (displaying long-running task progress) (Page covers streaming outputs from LLMs, pipelines, and custom data sources. Provides APIs for streaming like stream() and streamEvents(). Discusses auto-streaming chat models.)

[structured outputs](https://js.langchain.com/docs/concepts/structured_outputs/): LLM should read this page when (needing structured output from a model, creating chatbots or other applications requiring specific output formats, integrating structured output into a larger application) (Overview of structured output in LLMs, defining output schemas, methods for returning structured output like tool calling and JSON mode, using LangChain's withStructuredOutput helper)

[Text Splitters](https://js.langchain.com/docs/concepts/text_splitters/): LLM should read this page when (1) handling uneven document lengths, (2) working with models that have maximum input size constraints, (3) aiming to improve representation quality or retrieval precision. (Overview of different text splitting strategies: length-based, text structure-based, document structure-based, and semantic meaning-based. Covers the rationale, implementation, and use cases for each approach.)

[Tool binding](https://js.langchain.com/docs/concepts/tool_calling/#tool-binding): LLM should read this page when (needing to use tool calling functionality) (adding external tool capabilities to an LLM) (Overview of tool calling, creating tools, binding tools to models, models calling tools, executing tools. Key concepts and recommended usage.)

[Tools](https://js.langchain.com/docs/concepts/tools/): Line 1: 'LLM should read this page when (1) integrating external tools and APIs into an LLM application, (2) using chat models for tool calling, (3) understanding the concept of tools in LangChain' Line 2: '(An overview of LangChain tools, how to create custom tools using the tool function, configuring tool schemas, handling tool artifacts, and best practices for designing tools)'

[Tracing](https://js.langchain.com/docs/concepts/tracing/): LLM should read this page when (needing to understand tracing in LangChain, diagnosing issues in LangChain applications, seeking observability into chains and agents) (An explanation of tracing in LangChain, which involves recording a series of steps called runs as an application goes from input to output, providing visibility into individual model calls, retrievers, tools, and sub-chains)

[Vector stores](https://js.langchain.com/docs/concepts/vectorstores/): LLM should read this page when (developing applications that require semantic search or retrieval over unstructured data, integrating vector stores into an application, understanding how vector stores work). (Overview of vector stores, how they index and retrieve data based on semantic representations. Details on LangChain's vectorstore interface and integration. Covers adding/deleting documents, similarity search, metadata filtering, and advanced techniques.)

[Why LangChain?](https://js.langchain.com/docs/concepts/why_langchain/): LLM should read this page when (building applications that reason, exploring the LangChain ecosystem, evaluating standardized component interfaces) (Explains the goals of LangChain: standardizing component interfaces, enabling application orchestration, and providing observability/evaluation tools. Covers key LangChain components like chat models, retrievers, LangGraph for orchestration, and LangSmith for evaluations.)

[How-to guides](https://js.langchain.com/docs/how_to/): LLM should read this page when (it needs to understand how to use LangChain for specific tasks) (it needs guidance on building LLM applications with LangChain) (The page covers how-to guides for key LangChain features like prompt templates, chat models, document loaders, vectorstores, tools/agents, callbacks, and use cases like Q&A, extraction, chatbots, querying databases, and evaluation/tracing with LangSmith. It outlines how to accomplish specific goals with different components.)

[Tutorials](https://js.langchain.com/docs/tutorials/): LLM should read this page when (building LLM applications that require retrieval, question answering, or summarization components), (developing chatbots or agents that incorporate memory and calling external tools). (The page provides tutorials on building various LLM-powered applications like semantic search, classification, extraction, chatbots, retrieval augmented generation, question answering over SQL/graph databases, and text summarization using LangChain components.)

[Memory](https://langchain-ai.github.io/langgraphjs/concepts/memory/): LLM should read this page when (building a conversational AI, working with memories in LLMs, learning about short-term and long-term memory in LLMs) (Explains concepts of short-term and long-term memory in AI, techniques for managing conversation history and summarizing conversations for short-term memory, and approaches for writing, managing, and representing long-term memories like profiles, collections, instructions, and few-shot examples)

