Metadata-Version: 2.4
Name: tursi
Version: 0.2.0
Summary: A simple framework to deploy AI models locally with one command, no containers needed
Home-page: https://github.com/BlueTursi/tursi-ai
Author: Kresna Sucandra
Author-email: kresnasucandra@gmail.com
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: transformers
Requires-Dist: flask
Requires-Dist: torch==2.2.1
Requires-Dist: requests
Requires-Dist: numpy<2
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# tursi-ai

[![GitHub release](https://img.shields.io/github/v/release/BlueTursi/tursi-ai)](https://github.com/BlueTursi/tursi-ai/releases)

A simple, lightweight framework to deploy AI models locally with a single commandâ€”no Docker, no external services required.

## Overview

`tursi-ai` lets you run AI models (like text classification) on your machine with minimal setup. Our unique selling proposition: **"AI deployment, one command, no containers needed."** The base install is ~150-200MB, with an additional ~250MB for the default model on first run.

## Features

- **One-command deployment**: Start a model server with a single script.
- **No containers**: Runs directly in your Python environment.
- **Lightweight**: Minimal dependencies, small footprint.
- **Extensible**: Built for easy customization and growth.

## Getting Started

### Prerequisites

- Python 3.8+ (tested with 3.12)

### Installation

Install via PyPI:
```bash
pip install tursi
```

Or from source (for development)

1. Clone the repo:
```bash
git clone https://github.com/BlueTursi/tursi-ai.git
cd tursi-ai
```
2. Set up a virtual environment (required):
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```
3. Install:
```bash
pip install .
```

## Usage

### 1. Deploy a model:
```bash
tursi-engine up
```

Stop it with:
```bash
tursi-engine down
```

Customize:
```bash
tursi-engine up --model "distilbert-base-uncased-finetuned-sst-2-english" --host "127.0.0.1" --port 8080
```

### 2. Test the deployed model:

```bash
tursi-test --prompt "I love AI"
```

Or with a custom URL:

```bash
tursi-test --prompt "I love AI" --url "http://127.0.0.1:8080/predict"
```
---

## Project Structure

```text
tursi-ai/
â”œâ”€â”€ tursi/            # Core package
â”‚   â”œâ”€â”€ engine.py     # Deployment script with CLI
â”‚   â””â”€â”€ test.py       # Testing utility
â”œâ”€â”€ LICENSE           # MIT License
â”œâ”€â”€ README.md         # This file
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ setup.py          # PyPI setup
```

## Roadmap

- Add more CLI commands (e.g., status, down).
- Support additional model types.

## Contributing
Fork this repo, make changes, and submit a PR!

## License

[MIT License](/LICENSE)

## Acknowledgments

Built with ðŸ’™ using:
- Transformers
- Flask
- PyTorch

Built by [BlueTursi](https://bluetursi.com).
