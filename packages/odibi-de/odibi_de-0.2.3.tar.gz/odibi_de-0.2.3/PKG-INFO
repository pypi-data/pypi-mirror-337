Metadata-Version: 2.1
Name: odibi_de
Version: 0.2.3
Summary: Personal data engineering framework using Pandas and Spark
Home-page: https://github.com/henryodibi11/odibi_de_project
Author: Henry Odibi
Author-email: henryodibi@outlook.com
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE

# odibi_de

Henry Odibi's personal data engineering framework for scalable, modular, and testable data pipelines using **Pandas**, **Spark**, and **Azure**.

---

## ğŸš€ Features

- ğŸ”„ Readers & Savers for Pandas and Spark
- â˜ï¸ Supports both Cloud (Azure Blob Storage) and Local file systems
- ğŸ“¦ Built-in connectors for blob storage and SQL databases
- ğŸ“Š Handles CSV, JSON, Parquet, Avro, and Delta formats
- ğŸ§± Structured using SOLID principles and extensible factory patterns
- ğŸ§  Validations, transformations, and logging included (optional to use)

---

## ğŸ“¦ Installation

Clone the repo and install locally in **editable mode**:

```bash
git clone https://github.com/henryodibi11/odibi_de_project.git
cd odibi_de_project
pip install -e .

```
## ğŸ› ï¸ Usage

### âœ… Reading Local CSV File with Pandas

```python
from odibi_de import PandasReaderFactory, DataType

factory = PandasReaderFactory()
reader = factory.csv_reader("data.csv")
df = reader.read_data()

```
### â˜ï¸ Reading JSON from Azure Blob with Spark
```python
from pyspark.sql import SparkSession
from odibi_de import AzureBlobConnector, SparkReaderFactory, SparkCloudReaderProvider, DataType

spark = SparkSession.builder.appName("MyApp").getOrCreate()

connector = AzureBlobConnector("myaccount", "mykey")
factory = SparkReaderFactory()

provider = SparkCloudReaderProvider(factory, DataType.JSON, connector, spark)
reader = provider.create_reader("my-container", "path/to/data.json")
df = reader.read_data()
df.show()
```

### ğŸ’¾ Saving to Azure Blob Storage with Pandas

```python
from odibi_de import AzureBlobConnector, PandasSaverFactory, PandasCloudSaverProvider, DataType
import pandas as pd

data = pd.DataFrame({"name": ["Alice"], "age": [30]})
connector = AzureBlobConnector("myaccount", "mykey")
factory = PandasSaverFactory()
provider = PandasCloudSaverProvider(factory, connector)

saver = provider.create_saver(data, "my-container", "output.json", DataType.JSON)
saver.save_data(index=False)
```
### â˜ï¸ Reading JSON from Azure Blob with Spark
```python
from pyspark.sql import SparkSession
from odibi_de import AzureBlobConnector, SparkReaderFactory, SparkCloudReaderProvider, DataType

spark = SparkSession.builder.appName("MyApp").getOrCreate()

connector = AzureBlobConnector("myaccount", "mykey")
factory = SparkReaderFactory()

provider = SparkCloudReaderProvider(factory, DataType.JSON, connector, spark)
reader = provider.create_reader("my-container", "path/to/data.json")
df = reader.read_data()
df.show()

```

## ğŸ“ Project Structure
odibi_de_project/
â”‚
â”œâ”€â”€ odibi_de/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pandas_engine.py
â”‚   â”œâ”€â”€ spark_engine.py
â”‚   â”œâ”€â”€ core_types.py
â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pandas_factory.py
â”‚   â”œâ”€â”€ test_azure_connector.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt (optional)


## ğŸ§­ Future Plans
- ğŸ“š Add full documentation using Sphinx or Docusaurus

- ğŸŒ©ï¸ Add support for AWS S3 and Google Cloud Storage

- âš™ï¸ CLI interface for quick ingestion and transformation jobs

- ğŸ§¬ Library of pre-built transformations and schema validators

- âœ… Optional integration with Great Expectations or similar tools

## ğŸ™Œ Acknowledgments
Created and maintained by Henry Odibi to empower data engineers and analysts with scalable, clean, and modular tooling.
    "Do it right, and do it every day." ğŸ’ª
