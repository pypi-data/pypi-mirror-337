Metadata-Version: 2.4
Name: arelai
Version: 0.0.6
Summary: A library for creating games and training agents using reinforcement learning.
Author-email: Chandra Gummaluru <chandra.gummaluru@gmail.com>
Project-URL: Homepage, https://github.com/chandra-gummaluru/arelai
Project-URL: Issues, https://github.com/chandra-gummaluru/arelai/issues
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Classifier: License :: OSI Approved :: MIT License
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Dynamic: license-file

# Arelai

Arelai is a framework for creating games and training agents using reinforcement learning (RL). It includes core components like states, actions, observations, and players that can be customized for specific games.

## Usage

Using the framework is simple.

1. **Create a Custom Game**
   - Subclass `State`, `Action`, `Observation`, and `Game` to define your gameâ€™s rules and mechanics.

2. **Define Players**
   - Subclass `Player` to define how players interact with the game.

3. **Run the Game**
   - Create a `Game` object with players and an initial state, then call the `play()` method.

## Example

```python
class MyState(State):
    # Define the game state

class MyAction(Action):
    # Define an action structure
    
class MyObservation(Observation):
    # Define an observation structure
    

class MyPlayer(Player):
    def get_all_actions(self, state: MyState) -> list[MyAction]:
        # Return a list of actions

    def select_action(self, state: MyState) -> list[MyAction]:
        # Select an action for the player

class MyGame(Game):
    def log(self):
        # Define anything you want to log or do after each round

    def terminal(self) -> bool:
        # Define the game-ending condition

    def observe(self, player: MyPlayer, state: MyState) -> MyObservation:
        # Return the observation for the player

    def actions(self, player: MyPlayer, state: MyState) -> list[MyAction]:
        # Return all possible actions for the player

    def apply_action(self, state: State, action_profile: dict[UUID, Action]) -> State:
        # Apply the action profile and return the new state

    def calculate_reward(self,player: Player, old_state: MyState, action: MyAction, new_state: MyState) -> float:
        # Calculate the reward from the environment for the player
```
