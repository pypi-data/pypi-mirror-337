from enum import Enum
import json
import re  # æ–°å¢å¯¼å…¥
from collections import deque  # å¯¼å…¥åŒç«¯é˜Ÿåˆ—


class ProcessType(Enum):
    STEP_COUNT = "step_count"                           # å½“å‰å¤„äºagentçš„å“ªä¸€æ­¥
    MODEL_OUTPUT_THINKING = "model_output_thinking"     # æ¨¡å‹æµå¼è¾“å‡ºï¼Œæ€è€ƒå†…å®¹
    MODEL_OUTPUT_CODE = "model_output_code"             # æ¨¡å‹æµå¼è¾“å‡ºï¼Œä»£ç å†…å®¹
    PARSE = "parse"                                     # ä»£ç è§£æç»“æœ
    EXECUTION_LOGS = "execution_logs"                   # ä»£ç æ‰§è¡Œç»“æœ
    AGENT_NEW_RUN = "agent_new_run"                     # AgentåŸºæœ¬ä¿¡æ¯æ‰“å°
    FINAL_ANSWER = "final_answer"                       # æœ€ç»ˆæ€»ç»“å­—æ ·
    ERROR = "error"                                     # å¼‚å¸¸å­—æ®µ
    SEARCH_CONTENT = "search_content"                   # å·¥å…·ä¸­çš„æœç´¢å†…å®¹
    OTHER = "other"                                     # ä¸´æ—¶çš„å…¶ä»–å­—æ®µ
    TOKEN_COUNT = "token_count"                         # è®°å½•æ¯ä¸€ä¸ªstepä½¿ç”¨çš„tokenæ•°



class MessageObserver:
    def __init__(self, lang = "zh"):
        # ç»Ÿä¸€è¾“å‡ºç»™å‰ç«¯çš„å­—ç¬¦ä¸²ï¼Œæ”¹ä¸ºé˜Ÿåˆ—
        self.message_query = []

        # æ§åˆ¶è¾“å‡ºè¯­è¨€
        self.lang = lang
        
        # åˆå§‹åŒ–æ¶ˆæ¯ç±»å‹åˆ°è½¬æ¢å‡½æ•°çš„æ˜ å°„
        self._init_message_transformers()
        
        # åŒç«¯é˜Ÿåˆ—ç”¨äºå­˜å‚¨å’Œåˆ†ææœ€è¿‘çš„tokens
        self.token_buffer = deque()
        
        # å½“å‰è¾“å‡ºæ¨¡å¼ï¼šé»˜è®¤ä¸ºæ€è€ƒæ¨¡å¼
        self.current_mode = ProcessType.MODEL_OUTPUT_THINKING
        
        # ä»£ç å—æ ‡è®°æ¨¡å¼
        self.code_pattern = re.compile(r"ä»£ç (ï¼š|:)\s*```")

    def _init_message_transformers(self):
        """åˆå§‹åŒ–æ¶ˆæ¯ç±»å‹åˆ°è½¬æ¢å‡½æ•°çš„æ˜ å°„"""
        self.message_transformers = {
            ProcessType.AGENT_NEW_RUN: self._transform_agent_new_run,
            ProcessType.STEP_COUNT: self._transform_step_count,
            ProcessType.PARSE: self._transform_parse,
            ProcessType.EXECUTION_LOGS: self._transform_execution_logs,
            ProcessType.FINAL_ANSWER: self._transform_final_answer,
            ProcessType.OTHER: self._transform_none_process,
            ProcessType.SEARCH_CONTENT: self._transform_none_process,
            ProcessType.TOKEN_COUNT: self._transform_none_process,
            ProcessType.ERROR: self._transform_none_process,
        }
        
        # è¯­è¨€ç›¸å…³çš„æ¨¡æ¿å­—ç¬¦ä¸²
        self.templates = {
            "zh": {
                "step": "\n**æ­¥éª¤ {0}** \n",
                "parse": "\nğŸ› ï¸ ä½¿ç”¨Pythonè§£é‡Šå™¨æ‰§è¡Œä»£ç \n",
                "logs": "\nğŸ“ æ‰§è¡Œæ—¥å¿—\n",
                "final": "\n**æœ€ç»ˆå›ç­”:** \n{0}\n",
                "error": "\nğŸ’¥ Error\n"
            },
            "en": {
                "step": "\n**Step {0}** \n",
                "parse": "\nğŸ› ï¸ Used tool python_interpreter\n",
                "logs": "\nğŸ“ Execution Logs\n",
                "final": "\n**Final answer:** \n{0}\n",
                "error": "\nğŸ’¥ é”™è¯¯\n"
            }
        }

    def add_model_new_token(self, new_token):
        """
        è·å–æ¨¡å‹çš„æµå¼è¾“å‡ºï¼Œä½¿ç”¨åŒç«¯é˜Ÿåˆ—å®æ—¶åˆ†æå’Œåˆ†ç±»token
        """
        
        # å°†æ–°tokenæ·»åŠ åˆ°ç¼“å†²åŒº
        self.token_buffer.append(new_token)
        
        # å°†ç¼“å†²åŒºæ‹¼æ¥æˆæ–‡æœ¬è¿›è¡Œæ£€æŸ¥
        buffer_text = ''.join(self.token_buffer)
        
        # æŸ¥æ‰¾ä»£ç å—æ ‡è®°
        match = self.code_pattern.search(buffer_text)
        
        if match:
            # æ‰¾åˆ°äº†ä»£ç å—æ ‡è®°
            match_start = match.start()
            
            # å°†åŒ¹é…ä½ç½®ä¹‹å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒå‘é€
            prefix_text = buffer_text[:match_start]
            if prefix_text:
                self.message_query.append(Message(ProcessType.MODEL_OUTPUT_THINKING, prefix_text).to_json())
            
            # å°†åŒ¹é…éƒ¨åˆ†åŠä¹‹åçš„å†…å®¹ä½œä¸ºä»£ç å‘é€
            code_text = buffer_text[match_start:]
            if code_text:
                self.message_query.append(Message(ProcessType.MODEL_OUTPUT_CODE, code_text).to_json())
            
            # åˆ‡æ¢æ¨¡å¼
            self.current_mode = ProcessType.MODEL_OUTPUT_CODE
            
            # æ¸…ç©ºç¼“å†²åŒº
            self.token_buffer.clear()
        else:
            # æœªæ‰¾åˆ°ä»£ç å—æ ‡è®°ï¼Œä»é˜Ÿé¦–å–å‡ºå¹¶å‘é€ä¸€ä¸ªtokenï¼ˆå¦‚æœç¼“å†²åŒºé•¿åº¦è¶…è¿‡ä¸€å®šå¤§å°ï¼‰
            max_buffer_size = 10  # è®¾ç½®æœ€å¤§ç¼“å†²åŒºå¤§å°ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            while len(self.token_buffer) > max_buffer_size:
                oldest_token = self.token_buffer.popleft()
                self.message_query.append(Message(self.current_mode, oldest_token).to_json())

    def flush_remaining_tokens(self):
        """
        å°†åŒç«¯é˜Ÿåˆ—ä¸­å‰©ä½™çš„tokenå‘é€å‡ºå»
        """
        if not self.token_buffer:
            return
            
        # å°†ç¼“å†²åŒºæ‹¼æ¥æˆæ–‡æœ¬
        buffer_text = ''.join(self.token_buffer)
        self.message_query.append(Message(self.current_mode, buffer_text).to_json())
    
        # æ¸…ç©ºç¼“å†²åŒº
        self.token_buffer.clear()

    def add_message(self, agent_name, process_type, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°é˜Ÿåˆ—"""
        if process_type in self.message_transformers:
            transformer = self.message_transformers[process_type]
            formatted_content = transformer(content)
            self.message_query.append(Message(process_type, formatted_content).to_json())
    
    def _get_template(self, key):
        """è·å–å½“å‰è¯­è¨€å¯¹åº”çš„æ¨¡æ¿"""
        language = self.lang if self.lang in self.templates else "en"
        return self.templates[language][key]

    def _transform_none_process(self, content: str):
        """è¿”å›ä»»æ„æ¶ˆæ¯ï¼Œä¸åšå¤„ç†"""
        return content

    def _transform_agent_new_run(self, content: str):
        """è½¬æ¢agentæ–°è¿è¡Œçš„æ¶ˆæ¯"""
        return f"\n\n{content}\n\n"

    def _transform_step_count(self, content: str):
        """è½¬æ¢æ­¥éª¤è®¡æ•°çš„æ¶ˆæ¯"""
        return self._get_template("step").format(content)

    def _transform_parse(self, content: str):
        """è½¬æ¢è§£æç»“æœçš„æ¶ˆæ¯"""
        return self._get_template("parse") + f"```python\n{content}\n```\n"

    def _transform_execution_logs(self, content: str):
        """è½¬æ¢æ‰§è¡Œæ—¥å¿—çš„æ¶ˆæ¯"""
        return self._get_template("logs") + f"```bash\n{content}\n```\n"

    def _transform_final_answer(self, content: str):
        """è½¬æ¢æœ€ç»ˆç­”æ¡ˆçš„æ¶ˆæ¯"""
        return self._get_template("final").format(content)

    def _transform_error(self, content: str):
        """è½¬æ¢æœ€ç»ˆç­”æ¡ˆçš„æ¶ˆæ¯"""
        return self._get_template("error").format(content)

    def get_cached_message(self):
        cached_message = self.message_query
        self.message_query = []
        return cached_message


# å›ºå®šMessageObserverçš„è¾“å‡ºæ ¼å¼
class Message:
    def __init__(self, message_type: ProcessType, content):
        self.message_type = message_type
        self.content = content

    # ç”Ÿæˆjsonæ ¼å¼ï¼Œå¹¶è½¬æˆå­—ç¬¦ä¸²
    def to_json(self):
        return json.dumps({
            "type": self.message_type.value,
            "content": self.content
        }, ensure_ascii=False)

