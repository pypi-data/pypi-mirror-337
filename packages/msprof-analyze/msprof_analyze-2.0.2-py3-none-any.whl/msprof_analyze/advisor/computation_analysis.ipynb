{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from prettytable import PrettyTable, ALL\n",
    "from textwrap import fill\n",
    "from msprof_analyze.advisor.interface.interface import Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置profiling采集出来的数据,需要指定到的profiling目录是同一个工具采集的,并且需要采集l0级别以上\n",
    "profiling_path = r\"YOUR PROFILING PATH\"\n",
    "interface = Interface(profiling_path=profiling_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Dim问题识别\n",
    "\n",
    "Block Dim问题主要为识别相关core算子AI core核未打满或者Vector 核未打满问题,主要调优手段为AOE调优,由于AOE调优依赖静态shape,所以当所有算子都为动态shape时,将不会检测相关Block Dim问题.\n",
    "\n",
    "下列代码为样例,主要展示如何检测Block Dim类型问题,并获取相关问题检测结果:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询computation相关是否存在block dim问题\n",
    "# 如果profiling数据采集自非8.0.RC1的CANN版本,需要在训练/推理环境中执行: 'cat CANN安装目录/ascend-toolkit/latest/aarch64-linux/ascend_toolkit_install.info'命令查看version\n",
    "block_dim_result = interface.get_result(\"computation\", \"block_dim_analysis\", cann_version=\"7.0.RC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>problem</th>\n",
       "            <th>description</th>\n",
       "            <th>suggestion</th>\n",
       "            <th>problem count</th>\n",
       "            <th>total_time(us)</th>\n",
       "            <th>time ratio</th>\n",
       "            <th>income(us)</th>\n",
       "            <th>income ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>block dim</td>\n",
       "            <td>some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10<br>operator of task duration are as follows: Square, MatMulV2, BatchMatMul,<br>SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast</td>\n",
       "            <td>1. Optimize operator by AOE, such as: &#x27;aoe --job_type=2<br>--model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi<br>sor\\operator_tuning_file_20240613153259.cfg&#x27;</td>\n",
       "            <td>101</td>\n",
       "            <td>814.0199999999999</td>\n",
       "            <td>1.0</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| problem   | description                                                                      | suggestion                                                                       | problem count | total_time(us)    | time ratio | income(us) | income ratio |\n",
       "+-----------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| block dim | some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10 | 1. Optimize operator by AOE, such as: 'aoe --job_type=2                          | 101           | 814.0199999999999 | 1.0        |            |              |\n",
       "|           | operator of task duration are as follows: Square, MatMulV2, BatchMatMul,         | --model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi |               |                   |            |            |              |\n",
       "|           | SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast                     | sor\\operator_tuning_file_20240613153259.cfg'                                     |               |                   |            |            |              |\n",
       "+-----------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "problems = block_dim_result.get(\"problems\")\n",
    "if problems: # 如果存在相关问题则获取相关问题检测描述及建议\n",
    "    problem_table = PrettyTable(problems.get(\"headers\"))\n",
    "    for row in problems.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        problem_table.add_row(row)\n",
    "        \n",
    "    problem_table.align = \"l\"\n",
    "    problem_table.hrules = ALL\n",
    "    display(problem_table)\n",
    "else:\n",
    "    print(\"There is no suggestion related to block dim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>op_name</th>\n",
       "            <th>op_type</th>\n",
       "            <th>task_type</th>\n",
       "            <th>task_duration</th>\n",
       "            <th>income</th>\n",
       "            <th>block_dim</th>\n",
       "            <th>mix_block_dim</th>\n",
       "            <th>input_shapes</th>\n",
       "            <th>input_data_types</th>\n",
       "            <th>input_formats</th>\n",
       "            <th>output_shapes</th>\n",
       "            <th>output_data_types</th>\n",
       "            <th>output_formats</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/attention_norm-<br>LlamaRMSNorm/Square-op34Default/model-LlamaModel/layers-<br>CellList/0-LLamaDecodeLayer/attention_norm-LlamaRMSNorm/ReduceMean-op35</td>\n",
       "            <td>Square</td>\n",
       "            <td>AI_VECTOR_CORE</td>\n",
       "            <td>42.76</td>\n",
       "            <td>0</td>\n",
       "            <td>16</td>\n",
       "            <td>0</td>\n",
       "            <td>&quot;128,128&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "            <td>&quot;128,1&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/ffn_norm-<br>LlamaRMSNorm/Square-op77Default/model-LlamaModel/layers-<br>CellList/0-LLamaDecodeLayer/ffn_norm-LlamaRMSNorm/ReduceMean-op78</td>\n",
       "            <td>Square</td>\n",
       "            <td>AI_VECTOR_CORE</td>\n",
       "            <td>42.24</td>\n",
       "            <td>0</td>\n",
       "            <td>16</td>\n",
       "            <td>0</td>\n",
       "            <td>&quot;128,128&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "            <td>&quot;128,1&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Default/lm_head-Linear/MatMul-op213</td>\n",
       "            <td>MatMulV2</td>\n",
       "            <td>AI_CORE</td>\n",
       "            <td>39.02</td>\n",
       "            <td>0</td>\n",
       "            <td>20</td>\n",
       "            <td>0</td>\n",
       "            <td>&quot;128,128;128,32000&quot;</td>\n",
       "            <td>FLOAT16;FLOAT16</td>\n",
       "            <td>FORMAT_ND;FORMAT_ND</td>\n",
       "            <td>&quot;128,32000&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+--------+-----------+---------------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|                                   op_name                                   | op_type  |   task_type    | task_duration | income | block_dim | mix_block_dim |     input_shapes    | input_data_types |    input_formats    | output_shapes | output_data_types | output_formats |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+--------+-----------+---------------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "| Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/attention_norm- |  Square  | AI_VECTOR_CORE |     42.76     |   0    |     16    |       0       |      \"128,128\"      |      FLOAT       |         NCHW        |    \"128,1\"    |       FLOAT       |      NCHW      |\n",
       "|           LlamaRMSNorm/Square-op34Default/model-LlamaModel/layers-          |          |                |               |        |           |               |                     |                  |                     |               |                   |                |\n",
       "|   CellList/0-LLamaDecodeLayer/attention_norm-LlamaRMSNorm/ReduceMean-op35   |          |                |               |        |           |               |                     |                  |                     |               |                   |                |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+--------+-----------+---------------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|    Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/ffn_norm-    |  Square  | AI_VECTOR_CORE |     42.24     |   0    |     16    |       0       |      \"128,128\"      |      FLOAT       |         NCHW        |    \"128,1\"    |       FLOAT       |      NCHW      |\n",
       "|           LlamaRMSNorm/Square-op77Default/model-LlamaModel/layers-          |          |                |               |        |           |               |                     |                  |                     |               |                   |                |\n",
       "|      CellList/0-LLamaDecodeLayer/ffn_norm-LlamaRMSNorm/ReduceMean-op78      |          |                |               |        |           |               |                     |                  |                     |               |                   |                |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+--------+-----------+---------------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|                     Default/lm_head-Linear/MatMul-op213                     | MatMulV2 |    AI_CORE     |     39.02     |   0    |     20    |       0       | \"128,128;128,32000\" | FLOAT16;FLOAT16  | FORMAT_ND;FORMAT_ND |  \"128,32000\"  |       FLOAT       |   FORMAT_ND    |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+--------+-----------+---------------+---------------------+------------------+---------------------+---------------+-------------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if problems: # 如果存在相关问题则获取相关问题检测细节\n",
    "    block_dim = block_dim_result.get(\"block dim\")\n",
    "    block_dim_table = PrettyTable(block_dim.get(\"headers\"))\n",
    "    for row in block_dim.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        block_dim_table.add_row(row)\n",
    "\n",
    "    block_dim_table.hrules = ALL\n",
    "    display(block_dim_table[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator No Bound问题识别\n",
    "Operator No Bound问题主要为识别相关算子无mte, cube, vector, scalar相关bound问题,主要调优手段为AOE调优,由于AOE调优依赖静态shape,所以当所有算子都为动态shape时,将不会检测相关Operator No Bound问题.\n",
    "\n",
    "下列代码为样例,主要展示如何检测Operator No Bound类型问题,并获取相关问题检测结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable, ALL\n",
    "from textwrap import fill\n",
    "from msprof_analyze.advisor.interface.interface import Interface\n",
    "\n",
    "\n",
    "# 配置profiling采集出来的数据,需要指定到的profiling目录是同一个工具采集的,并且需要采集l0级别以上\n",
    "profiling_path = r\"YOUR PROFILING PATH\"\n",
    "interface = Interface(profiling_path=profiling_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询computation相关是否存在operator no bound问题\n",
    "# 如果profiling数据采集自非8.0.RC1的CANN版本,需要在训练/推理环境中执行: 'cat CANN安装目录/ascend-toolkit/latest/aarch64-linux/ascend_toolkit_install.info'命令查看version\n",
    "operator_no_bound_result = interface.get_result(\"computation\", \"operator_no_bound_analysis\", cann_version=\"7.0.RC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>problem</th>\n",
       "            <th>description</th>\n",
       "            <th>suggestion</th>\n",
       "            <th>problem count</th>\n",
       "            <th>total_time(us)</th>\n",
       "            <th>time ratio</th>\n",
       "            <th>income(us)</th>\n",
       "            <th>income ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>block dim</td>\n",
       "            <td>some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10<br>operator of task duration are as follows: Square, MatMulV2, BatchMatMul,<br>SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast</td>\n",
       "            <td>1. Optimize operator by AOE, such as: &#x27;aoe --job_type=2<br>--model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi<br>sor\\operator_tuning_file_20240613153259.cfg&#x27;</td>\n",
       "            <td>101</td>\n",
       "            <td>814.0199999999999</td>\n",
       "            <td>1.0</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>operator no bound</td>\n",
       "            <td>There is no mte, cube, vector, scalar ratio is more than 80.00%; Top task<br>duration operators need to be tuned are as follows:  Square, MatMulV2,<br>BatchMatMul,  SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast</td>\n",
       "            <td>1. Optimize operator by AOE, such as: &#x27;aoe --job_type=2<br>--model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi<br>sor\\operator_tuning_file_20240613153259.cfg&#x27;</td>\n",
       "            <td>95</td>\n",
       "            <td>814.0199999999999</td>\n",
       "            <td>0.7985</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| problem           | description                                                                      | suggestion                                                                       | problem count | total_time(us)    | time ratio | income(us) | income ratio |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| block dim         | some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10 | 1. Optimize operator by AOE, such as: 'aoe --job_type=2                          | 101           | 814.0199999999999 | 1.0        |            |              |\n",
       "|                   | operator of task duration are as follows: Square, MatMulV2, BatchMatMul,         | --model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi |               |                   |            |            |              |\n",
       "|                   | SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast                     | sor\\operator_tuning_file_20240613153259.cfg'                                     |               |                   |            |            |              |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| operator no bound | There is no mte, cube, vector, scalar ratio is more than 80.00%; Top task        | 1. Optimize operator by AOE, such as: 'aoe --job_type=2                          | 95            | 814.0199999999999 | 0.7985     |            |              |\n",
       "|                   | duration operators need to be tuned are as follows:  Square, MatMulV2,           | --model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi |               |                   |            |            |              |\n",
       "|                   | BatchMatMul,  SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast       | sor\\operator_tuning_file_20240613153259.cfg'                                     |               |                   |            |            |              |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "problems = operator_no_bound_result.get(\"problems\")\n",
    "problem_table = PrettyTable(problems.get(\"headers\"))\n",
    "if problems: # 如果存在相关问题则获取相关问题检测描述及建议\n",
    "    for row in problems.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        problem_table.add_row(row)\n",
    "\n",
    "    problem_table.align = \"l\"\n",
    "    problem_table.hrules = ALL\n",
    "    display(problem_table)\n",
    "else:\n",
    "    print(\"There is no suggestion related to operator no bound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>op_name</th>\n",
       "            <th>op_type</th>\n",
       "            <th>task_type</th>\n",
       "            <th>task_duration</th>\n",
       "            <th>vec_ratio</th>\n",
       "            <th>mac_ratio</th>\n",
       "            <th>scalar_ratio</th>\n",
       "            <th>mte1_ratio</th>\n",
       "            <th>mte2_ratio</th>\n",
       "            <th>mte3_ratio</th>\n",
       "            <th>block_dim</th>\n",
       "            <th>input_shapes</th>\n",
       "            <th>input_data_types</th>\n",
       "            <th>input_formats</th>\n",
       "            <th>output_shapes</th>\n",
       "            <th>output_data_types</th>\n",
       "            <th>output_formats</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/attention_norm-<br>LlamaRMSNorm/Square-op34Default/model-LlamaModel/layers-<br>CellList/0-LLamaDecodeLayer/attention_norm-LlamaRMSNorm/ReduceMean-op35</td>\n",
       "            <td>Square</td>\n",
       "            <td>AI_VECTOR_CORE</td>\n",
       "            <td>42.76</td>\n",
       "            <td>0.4654</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0.0056</td>\n",
       "            <td>16</td>\n",
       "            <td>&quot;128,128&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "            <td>&quot;128,1&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/ffn_norm-<br>LlamaRMSNorm/Square-op77Default/model-LlamaModel/layers-<br>CellList/0-LLamaDecodeLayer/ffn_norm-LlamaRMSNorm/ReduceMean-op78</td>\n",
       "            <td>Square</td>\n",
       "            <td>AI_VECTOR_CORE</td>\n",
       "            <td>42.24</td>\n",
       "            <td>0.466</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0</td>\n",
       "            <td>0.0062</td>\n",
       "            <td>16</td>\n",
       "            <td>&quot;128,128&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "            <td>&quot;128,1&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>NCHW</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Default/lm_head-Linear/MatMul-op213</td>\n",
       "            <td>MatMulV2</td>\n",
       "            <td>AI_CORE</td>\n",
       "            <td>39.02</td>\n",
       "            <td>0</td>\n",
       "            <td>0.1105</td>\n",
       "            <td>0.0119</td>\n",
       "            <td>0.0857</td>\n",
       "            <td>0.4284</td>\n",
       "            <td>0</td>\n",
       "            <td>20</td>\n",
       "            <td>&quot;128,128;128,32000&quot;</td>\n",
       "            <td>FLOAT16;FLOAT16</td>\n",
       "            <td>FORMAT_ND;FORMAT_ND</td>\n",
       "            <td>&quot;128,32000&quot;</td>\n",
       "            <td>FLOAT</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+-----------+-----------+--------------+------------+------------+------------+-----------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|                                   op_name                                   | op_type  |   task_type    | task_duration | vec_ratio | mac_ratio | scalar_ratio | mte1_ratio | mte2_ratio | mte3_ratio | block_dim |     input_shapes    | input_data_types |    input_formats    | output_shapes | output_data_types | output_formats |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+-----------+-----------+--------------+------------+------------+------------+-----------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "| Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/attention_norm- |  Square  | AI_VECTOR_CORE |     42.76     |   0.4654  |     0     |      0       |     0      |     0      |   0.0056   |     16    |      \"128,128\"      |      FLOAT       |         NCHW        |    \"128,1\"    |       FLOAT       |      NCHW      |\n",
       "|           LlamaRMSNorm/Square-op34Default/model-LlamaModel/layers-          |          |                |               |           |           |              |            |            |            |           |                     |                  |                     |               |                   |                |\n",
       "|   CellList/0-LLamaDecodeLayer/attention_norm-LlamaRMSNorm/ReduceMean-op35   |          |                |               |           |           |              |            |            |            |           |                     |                  |                     |               |                   |                |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+-----------+-----------+--------------+------------+------------+------------+-----------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|    Default/model-LlamaModel/layers-CellList/0-LLamaDecodeLayer/ffn_norm-    |  Square  | AI_VECTOR_CORE |     42.24     |   0.466   |     0     |      0       |     0      |     0      |   0.0062   |     16    |      \"128,128\"      |      FLOAT       |         NCHW        |    \"128,1\"    |       FLOAT       |      NCHW      |\n",
       "|           LlamaRMSNorm/Square-op77Default/model-LlamaModel/layers-          |          |                |               |           |           |              |            |            |            |           |                     |                  |                     |               |                   |                |\n",
       "|      CellList/0-LLamaDecodeLayer/ffn_norm-LlamaRMSNorm/ReduceMean-op78      |          |                |               |           |           |              |            |            |            |           |                     |                  |                     |               |                   |                |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+-----------+-----------+--------------+------------+------------+------------+-----------+---------------------+------------------+---------------------+---------------+-------------------+----------------+\n",
       "|                     Default/lm_head-Linear/MatMul-op213                     | MatMulV2 |    AI_CORE     |     39.02     |     0     |   0.1105  |    0.0119    |   0.0857   |   0.4284   |     0      |     20    | \"128,128;128,32000\" | FLOAT16;FLOAT16  | FORMAT_ND;FORMAT_ND |  \"128,32000\"  |       FLOAT       |   FORMAT_ND    |\n",
       "+-----------------------------------------------------------------------------+----------+----------------+---------------+-----------+-----------+--------------+------------+------------+------------+-----------+---------------------+------------------+---------------------+---------------+-------------------+----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if problems: # 如果存在相关问题则获取相关问题检测细节\n",
    "    operator_no_bound = operator_no_bound_result.get(\"operator no bound\")\n",
    "    operator_no_bound_table = PrettyTable(operator_no_bound.get(\"headers\"))\n",
    "    for row in operator_no_bound.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        operator_no_bound_table.add_row(row)\n",
    "    operator_no_bound_table.hrules = ALL\n",
    "    display(operator_no_bound_table[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AICPU问题识别\n",
    "AICPU问题主要为识别相关算子执行时跑到AICPU上计算,并没有利用到AI CORE的计算能力的场景,主要调优手段为修改相关代码来避免AICPU算子,可参见相关资料,来避免AICPU算子的问题:\n",
    "https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md\n",
    "\n",
    "下列代码为样例,主要展示如何检测Dynamic Shape类型问题,并获取相关问题检测结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable, ALL\n",
    "from textwrap import fill\n",
    "from msprof_analyze.advisor.interface.interface import Interface\n",
    "\n",
    "\n",
    "# 配置profiling采集出来的数据,需要指定到的profiling目录是同一个工具采集的,并且需要采集l0级别以上\n",
    "profiling_path = r\"YOUR PROFILING PATH\"\n",
    "interface = Interface(profiling_path=profiling_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please ensure only one trace_view.json in C:\\personalC\\profiling_data, there will analyze first timeline profiling data.\n",
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "# 查询computation相关是否存在aicpu问题\n",
    "# 如果profiling数据采集自非8.0.RC1的CANN版本,需要在训练/推理环境中执行: 'cat CANN安装目录/ascend-toolkit/latest/aarch64-linux/ascend_toolkit_install.info'命令查看version\n",
    "aicpu_result = interface.get_result(\"computation\", \"aicpu_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>problem</th>\n",
       "            <th>description</th>\n",
       "            <th>suggestion</th>\n",
       "            <th>problem count</th>\n",
       "            <th>total_time(us)</th>\n",
       "            <th>time ratio</th>\n",
       "            <th>income(us)</th>\n",
       "            <th>income ratio</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>block dim</td>\n",
       "            <td>some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10<br>operator of task duration are as follows: Square, MatMulV2, BatchMatMul,<br>SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast</td>\n",
       "            <td>1. Optimize operator by AOE, such as: &#x27;aoe --job_type=2<br>--model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi<br>sor\\operator_tuning_file_20240613153259.cfg&#x27;</td>\n",
       "            <td>101</td>\n",
       "            <td>814.0199999999999</td>\n",
       "            <td>1.0</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>operator no bound</td>\n",
       "            <td>There is no mte, cube, vector, scalar ratio is more than 80.00%; Top task<br>duration operators need to be tuned are as follows:  Square, MatMulV2,<br>BatchMatMul,  SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast</td>\n",
       "            <td>1. Optimize operator by AOE, such as: &#x27;aoe --job_type=2<br>--model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi<br>sor\\operator_tuning_file_20240613153259.cfg&#x27;</td>\n",
       "            <td>95</td>\n",
       "            <td>814.0199999999999</td>\n",
       "            <td>0.7985</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>AICPU operator</td>\n",
       "            <td>Some operators and task duration exceed 20 us, such as : Cast</td>\n",
       "            <td>1. Modify code to avoid aicpu operator</td>\n",
       "            <td>39</td>\n",
       "            <td>686568.860000001</td>\n",
       "            <td>0.0189</td>\n",
       "            <td></td>\n",
       "            <td></td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| problem           | description                                                                      | suggestion                                                                       | problem count | total_time(us)    | time ratio | income(us) | income ratio |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| block dim         | some operator does not make full use of 25 ai core or 50 ai vector core;  Top-10 | 1. Optimize operator by AOE, such as: 'aoe --job_type=2                          | 101           | 814.0199999999999 | 1.0        |            |              |\n",
       "|                   | operator of task duration are as follows: Square, MatMulV2, BatchMatMul,         | --model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi |               |                   |            |            |              |\n",
       "|                   | SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast                     | sor\\operator_tuning_file_20240613153259.cfg'                                     |               |                   |            |            |              |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| operator no bound | There is no mte, cube, vector, scalar ratio is more than 80.00%; Top task        | 1. Optimize operator by AOE, such as: 'aoe --job_type=2                          | 95            | 814.0199999999999 | 0.7985     |            |              |\n",
       "|                   | duration operators need to be tuned are as follows:  Square, MatMulV2,           | --model_path=$user_dump_path --tune_ops_file=c:\\personalC\\code\\att\\profiler\\advi |               |                   |            |            |              |\n",
       "|                   | BatchMatMul,  SoftmaxV2, Mul, Transpose,  Assign, GatherV2, Sigmoid,  Cast       | sor\\operator_tuning_file_20240613153259.cfg'                                     |               |                   |            |            |              |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+\n",
       "| AICPU operator    | Some operators and task duration exceed 20 us, such as : Cast                    | 1. Modify code to avoid aicpu operator                                           | 39            | 686568.860000001  | 0.0189     |            |              |\n",
       "+-------------------+----------------------------------------------------------------------------------+----------------------------------------------------------------------------------+---------------+-------------------+------------+------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "problems = aicpu_result.get(\"problems\")\n",
    "if problems: # 如果存在相关问题则获取相关问题检测描述及建议\n",
    "    problem_table = PrettyTable(problems.get(\"headers\"))\n",
    "    for row in problems.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        problem_table.add_row(row)\n",
    "\n",
    "    problem_table.align = \"l\"\n",
    "    problem_table.hrules = ALL\n",
    "    display(problem_table)\n",
    "else:\n",
    "    print(\"There is no suggestion related to operator no bound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>op_name</th>\n",
       "            <th>op_type</th>\n",
       "            <th>task_duration</th>\n",
       "            <th>input_shapes</th>\n",
       "            <th>input_data_types</th>\n",
       "            <th>input_formats</th>\n",
       "            <th>output_shapes</th>\n",
       "            <th>output_data_types</th>\n",
       "            <th>output_formats</th>\n",
       "            <th>stack_info</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>trans_Cast_5</td>\n",
       "            <td>Cast</td>\n",
       "            <td>493.64</td>\n",
       "            <td>&quot;&quot;</td>\n",
       "            <td>INT32</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "            <td>&quot;&quot;</td>\n",
       "            <td>UINT64</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "            <td>/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py(1279):<br>dropout;  /usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/dropout.py(58): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/language_model.py(236): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/language_model.py(425): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/gpt_model.py(84): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/module.py(184): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/distributed.py(58): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>../../pretrain_gpt.py(88): forward_step;<br>/profiling_auto_GPT3/megatron/schedules.py(118): forward_step;<br>/home/s30040711/Megatron-<br>LM/megatron_npu_adaptor/megatron_npu/adaptor_schedules.py(96):<br>forward_backward_no_pipelining;  /profiling_auto_GPT3/megatron/training.py(419):<br>train_step;  /profiling_auto_GPT3/megatron/training.py(837): train;<br>/profiling_auto_GPT3/megatron/training.py(152): pretrain;<br>../../pretrain_gpt.py(122): &lt;module&gt;</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>trans_Cast_5</td>\n",
       "            <td>Cast</td>\n",
       "            <td>413.4</td>\n",
       "            <td>&quot;&quot;</td>\n",
       "            <td>INT32</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "            <td>&quot;&quot;</td>\n",
       "            <td>UINT64</td>\n",
       "            <td>FORMAT_ND</td>\n",
       "            <td>/usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py(1279):<br>dropout;  /usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/dropout.py(58): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/language_model.py(236): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/language_model.py(425): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/gpt_model.py(84): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/module.py(184): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>/profiling_auto_GPT3/megatron/model/distributed.py(58): forward;<br>/usr/local/python3.7.5/lib/python3.7/site-<br>packages/torch/nn/modules/module.py(1110): _call_impl;<br>../../pretrain_gpt.py(88): forward_step;<br>/profiling_auto_GPT3/megatron/schedules.py(118): forward_step;<br>/home/s30040711/Megatron-<br>LM/megatron_npu_adaptor/megatron_npu/adaptor_schedules.py(109):<br>forward_backward_no_pipelining;  /profiling_auto_GPT3/megatron/training.py(419):<br>train_step;  /profiling_auto_GPT3/megatron/training.py(837): train;<br>/profiling_auto_GPT3/megatron/training.py(152): pretrain;<br>../../pretrain_gpt.py(122): &lt;module&gt;</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------+---------+---------------+--------------+------------------+---------------+---------------+-------------------+----------------+----------------------------------------------------------------------------------+\n",
       "|   op_name    | op_type | task_duration | input_shapes | input_data_types | input_formats | output_shapes | output_data_types | output_formats |                                    stack_info                                    |\n",
       "+--------------+---------+---------------+--------------+------------------+---------------+---------------+-------------------+----------------+----------------------------------------------------------------------------------+\n",
       "| trans_Cast_5 |   Cast  |     493.64    |      \"\"      |      INT32       |   FORMAT_ND   |       \"\"      |       UINT64      |   FORMAT_ND    | /usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py(1279): |\n",
       "|              |         |               |              |                  |               |               |                   |                |               dropout;  /usr/local/python3.7.5/lib/python3.7/site-               |\n",
       "|              |         |               |              |                  |               |               |                   |                |                packages/torch/nn/modules/dropout.py(58): forward;                |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |       /profiling_auto_GPT3/megatron/model/language_model.py(236): forward;       |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |       /profiling_auto_GPT3/megatron/model/language_model.py(425): forward;       |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |          /profiling_auto_GPT3/megatron/model/gpt_model.py(84): forward;          |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |           /profiling_auto_GPT3/megatron/model/module.py(184): forward;           |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |         /profiling_auto_GPT3/megatron/model/distributed.py(58): forward;         |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |                     ../../pretrain_gpt.py(88): forward_step;                     |\n",
       "|              |         |               |              |                  |               |               |                   |                |          /profiling_auto_GPT3/megatron/schedules.py(118): forward_step;          |\n",
       "|              |         |               |              |                  |               |               |                   |                |                            /home/s30040711/Megatron-                             |\n",
       "|              |         |               |              |                  |               |               |                   |                |          LM/megatron_npu_adaptor/megatron_npu/adaptor_schedules.py(96):          |\n",
       "|              |         |               |              |                  |               |               |                   |                | forward_backward_no_pipelining;  /profiling_auto_GPT3/megatron/training.py(419): |\n",
       "|              |         |               |              |                  |               |               |                   |                |       train_step;  /profiling_auto_GPT3/megatron/training.py(837): train;        |\n",
       "|              |         |               |              |                  |               |               |                   |                |            /profiling_auto_GPT3/megatron/training.py(152): pretrain;             |\n",
       "|              |         |               |              |                  |               |               |                   |                |                       ../../pretrain_gpt.py(122): <module>                       |\n",
       "+--------------+---------+---------------+--------------+------------------+---------------+---------------+-------------------+----------------+----------------------------------------------------------------------------------+\n",
       "| trans_Cast_5 |   Cast  |     413.4     |      \"\"      |      INT32       |   FORMAT_ND   |       \"\"      |       UINT64      |   FORMAT_ND    | /usr/local/python3.7.5/lib/python3.7/site-packages/torch/nn/functional.py(1279): |\n",
       "|              |         |               |              |                  |               |               |                   |                |               dropout;  /usr/local/python3.7.5/lib/python3.7/site-               |\n",
       "|              |         |               |              |                  |               |               |                   |                |                packages/torch/nn/modules/dropout.py(58): forward;                |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |       /profiling_auto_GPT3/megatron/model/language_model.py(236): forward;       |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |       /profiling_auto_GPT3/megatron/model/language_model.py(425): forward;       |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |          /profiling_auto_GPT3/megatron/model/gpt_model.py(84): forward;          |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |           /profiling_auto_GPT3/megatron/model/module.py(184): forward;           |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |         /profiling_auto_GPT3/megatron/model/distributed.py(58): forward;         |\n",
       "|              |         |               |              |                  |               |               |                   |                |                    /usr/local/python3.7.5/lib/python3.7/site-                    |\n",
       "|              |         |               |              |                  |               |               |                   |                |              packages/torch/nn/modules/module.py(1110): _call_impl;              |\n",
       "|              |         |               |              |                  |               |               |                   |                |                     ../../pretrain_gpt.py(88): forward_step;                     |\n",
       "|              |         |               |              |                  |               |               |                   |                |          /profiling_auto_GPT3/megatron/schedules.py(118): forward_step;          |\n",
       "|              |         |               |              |                  |               |               |                   |                |                            /home/s30040711/Megatron-                             |\n",
       "|              |         |               |              |                  |               |               |                   |                |         LM/megatron_npu_adaptor/megatron_npu/adaptor_schedules.py(109):          |\n",
       "|              |         |               |              |                  |               |               |                   |                | forward_backward_no_pipelining;  /profiling_auto_GPT3/megatron/training.py(419): |\n",
       "|              |         |               |              |                  |               |               |                   |                |       train_step;  /profiling_auto_GPT3/megatron/training.py(837): train;        |\n",
       "|              |         |               |              |                  |               |               |                   |                |            /profiling_auto_GPT3/megatron/training.py(152): pretrain;             |\n",
       "|              |         |               |              |                  |               |               |                   |                |                       ../../pretrain_gpt.py(122): <module>                       |\n",
       "+--------------+---------+---------------+--------------+------------------+---------------+---------------+-------------------+----------------+----------------------------------------------------------------------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if problems: # 如果存在相关问题则获取相关问题检测细节\n",
    "    aicpu = aicpu_result.get(\"AICPU operator\")\n",
    "    aicpu_table = PrettyTable(aicpu.get(\"headers\"))\n",
    "    for row in aicpu.get(\"data\"):\n",
    "        row = [fill(str(element), width=80) for element in row]\n",
    "        aicpu_table.add_row(row)\n",
    "    aicpu_table.hrules = ALL\n",
    "    display(aicpu_table[:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
